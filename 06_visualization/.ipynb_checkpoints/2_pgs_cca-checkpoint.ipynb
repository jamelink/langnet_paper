{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "453dafb7-d07a-4126-8e77-c3f440ba6309",
   "metadata": {},
   "source": [
    "## Polygenic scores CCA\n",
    "Inputs:\n",
    "- polygenic scores from reading, dyslexia and handedness GWASes using PRS-CS\n",
    "- language network connectivity and asymmetries based on the AICHA analysis\n",
    "\n",
    "Computations:\n",
    "- residualization for covariates and quantile transform\n",
    "- Canonical Correlation Analysis using scikit-learn\n",
    "- Permutation test (permuting polygenic scores) for significance testing of correlation value\n",
    "\n",
    "Output:\n",
    "- figure that shows loadings and overall association pattern with each of the polygenic scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7098a507-d049-4b15-aa3c-45a59d4fbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c01608-7040-405f-b345-47f30dff2a0b",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ecff222-10b6-4925-9297-a891741f9dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_pgs_chr(fn, chr_no):\n",
    "    data = pd.read_csv(fn, sep=\"\\s+\", engine=\"python\", na_values='-9')\n",
    "    return data.rename(columns={\"SCORESUM\":\"score_c{}\".format(chr_no)})\n",
    "\n",
    "def get_pgs(fn, pheno_name):\n",
    "    file_list = [fn.format(pheno_name, chr_no) for chr_no in range(1,23)]\n",
    "    data = pd.concat(map(read_pgs_chr, file_list, range(1,23)), join=\"inner\", axis=1).T.drop_duplicates().T\n",
    "    chrom_scores = [\"score_c{0}\".format(i) for i in range(1,23)]\n",
    "    data[\"score_{0}\".format(pheno_name)] = np.sum(data[chrom_scores].to_numpy(),axis=1)\n",
    "    return data[[\"FID\", \"score_{0}\".format(pheno_name)]]\n",
    "\n",
    "def get_all_pgs(fn, pheno_list):\n",
    "    return pd.concat(map(get_pgs, [fn]*len(pheno_list), pheno_list), join=\"inner\", axis=1).T.drop_duplicates().T    \n",
    "\n",
    "def load_column_names(fn):\n",
    "    return [str(x) for x in open( fn ).read().split('\\n')[:-1] ]\n",
    "\n",
    "def residualize(data, covs, drop_all=True):\n",
    "    #input_file = file_name + '.csv'\n",
    "    #data = pd.read_csv(input_file)\n",
    "    #data = data.set_index(data.columns[0]) \n",
    "    #data = data.loc[exome_subs]\n",
    "\n",
    "    if drop_all:\n",
    "        data = data.dropna()\n",
    "        data = data.sort_index()\n",
    "        #data[data.isnull()] = 0\n",
    "        missing_sub = list((set(list(covs.index.values)).difference(list(data.index.values))))\n",
    "        print(\"No. subjects missing from subject file: \", len(missing_sub))\n",
    "        covs=covs.loc[data.index.values]\n",
    "\n",
    "        #define new dataframe\n",
    "        data_new=pd.DataFrame(columns=data.columns, index=data.index.values)\n",
    "\n",
    "        #residualize\n",
    "        for dep_var in data.columns: \n",
    "            model = sm.OLS(data[dep_var], exog=covs)\n",
    "            results = model.fit()\n",
    "            data_new[dep_var] = results.resid\n",
    "    \n",
    "            \n",
    "    #quantile transformation\n",
    "    X = data_new.to_numpy()\n",
    "    data_new2 = pd.DataFrame(data=quantile_transform(X, n_quantiles=1000, output_distribution='normal', random_state=0, copy=True), columns=data_new.columns, index=data_new.index.values)\n",
    "    return data_new2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8649a6fe-0c4d-480a-abce-102d1c3910fd",
   "metadata": {},
   "source": [
    "#### CCA function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74cefda0-3756-49a2-a0c4-fc968661cfb1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "def add_row(df, new_data, column_names, index_name):\n",
    "    df_new = pd.DataFrame(data=new_data.reshape((1, len(column_names))), columns=column_names, index=[index_name])\n",
    "    return pd.concat([df, df_new], axis=0)\n",
    "\n",
    "def CCA_core(X,Y):\n",
    "    #fit data\n",
    "    ca = CCA(n_components=1)\n",
    "    ca.fit(X, Y)\n",
    "    X_c, Y_c = ca.transform(X, Y)\n",
    "    \n",
    "    #add to dataframes\n",
    "    r, p = pearsonr(X_c[:, 0], Y_c[:, 0])\n",
    "    loadings = ca.coef_\n",
    "    return r, loadings\n",
    "\n",
    "def greater(null_distribution, observed, n_resamples):\n",
    "    \"\"\"\n",
    "    from scipy.stats.permutation_test\n",
    "    https://github.com/scipy/scipy/blob/v1.11.1/scipy/stats/_resampling.py#L1234-L1707\n",
    "    \"\"\"\n",
    "    cmps = null_distribution >= observed\n",
    "    pvalues = (cmps.sum(axis=0) + 1) / (n_resamples + 1)  # see [1]\n",
    "    return pvalues\n",
    "\n",
    "def CCA_wrap(all_data, df_loadings, df_corrs, df_null_dist, pheno_prs, brain_phenos, n_perm, seed=2023):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    #get right data\n",
    "    X = all_data[pheno_prs].to_numpy().reshape(-1, 1)\n",
    "    Y = all_data[brain_phenos].to_numpy()\n",
    "    \n",
    "    rng = default_rng(seed)\n",
    "    \n",
    "    r_distribution = np.zeros(n_perm)\n",
    "    \n",
    "    for x in tqdm(range(n_perm)):\n",
    "        X_perm = rng.permutation(X)\n",
    "        r, _ = CCA_core(X_perm, Y)\n",
    "        r_distribution[x] = r\n",
    "        \n",
    "    #final loadings\n",
    "    r, loadings = CCA_core(X, Y)\n",
    "    p = greater(r_distribution, r, n_perm)\n",
    "    \n",
    "    df_null_dist = add_row(df_null_dist, r_distribution, range(n_perm), pheno_prs)\n",
    "    df_corrs = add_row(df_corrs, np.array([r, p]), \"R P\".split(), pheno_prs)\n",
    "    df_loadings = add_row(df_loadings, np.array(loadings), brain_phenos, pheno_prs)\n",
    "    \n",
    "    return df_corrs, df_loadings, df_null_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d25670-356e-4b5f-8ae3-f92a2cd5837a",
   "metadata": {},
   "source": [
    "#### Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e2f1ed6-ed03-4476-bd66-95a3361bf069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nilearn import plotting, image\n",
    "from matplotlib import cm\n",
    "\n",
    "def load_column_names(fn):\n",
    "    return [str(x) for x in open( fn ).read().split('\\n')[:-1] ]  \n",
    "\n",
    "def get_edge_names(list_names):\n",
    "    \"\"\"\n",
    "    Returns edge combinations for edges\n",
    "    \"\"\"\n",
    "    df_names=pd.DataFrame(index=list_names, columns=list_names)\n",
    "    for i in range(len(list_names)):\n",
    "        for j in range(len(list_names)):\n",
    "            df_names.iloc[i, j] = list_names[i]+\"*\"+list_names[j]\n",
    "            \n",
    "    #heritable = load_column_names(\"/data/clusterfs/lag/users/jitame/SENT_CORE/heritable_edges.txt\") + load_column_names(\"/data/clusterfs/lag/users/jitame/SENT_CORE/heritable_edges_asym.txt\")\n",
    "    #heritable = [\"sent_edges_\"+x for x in heritable]\n",
    "    \n",
    "    return [x for x in list(df_names.to_numpy()[np.triu_indices(len(list_names), k=1)].flatten()) if x in heritable]\n",
    "\n",
    "\n",
    "def get_idx(cat):\n",
    "    \"\"\"\n",
    "    Returns indices for category\n",
    "    \"\"\"\n",
    "    sent_core_l_ind = [2, 30, 32, 40, 56, 98, 102, 146, 148, 166, 168, 170, 172, 174, 182, 184, 222, 224]\n",
    "    sent_core_r_ind = [3, 31, 33, 41, 57, 99, 103, 147, 149, 167, 169, 171, 173, 175, 183, 185, 223, 225]\n",
    "    sent_core_bi_ind = sorted(sent_core_l_ind + sent_core_r_ind)\n",
    "    \n",
    "    if cat == \"edges\":\n",
    "        return sent_core_bi_ind\n",
    "    elif cat == \"edges_HD\":\n",
    "        return sent_core_l_ind\n",
    "    \n",
    "    \n",
    "def set_up_coordinates(cat):\n",
    "    \"\"\"\n",
    "    get coordinates for plot\n",
    "    \"\"\"\n",
    "    #set up atlas + coordinates\n",
    "    aicha_atlas = \"/data/workspaces/lag/workspaces/lg-ukbiobank/projects/multilateral/FuncNet_AICHA/segs/AICHA.nii\"\n",
    "    aicha_img = image.load_img(aicha_atlas)\n",
    "    aicha_coords = plotting.find_parcellation_cut_coords(aicha_img)\n",
    "    \n",
    "    #indices\n",
    "    idx = get_idx(cat)\n",
    "\n",
    "    #get coordinates and names\n",
    "    return aicha_coords[idx, :]\n",
    "\n",
    "def get_names_aicha(cat):\n",
    "    \"\"\"\n",
    "    Return node names\n",
    "    \"\"\"\n",
    "    aicha_test = \"/data/clusterfs/lag/projects/lg-ukbiobank/working_data/imaging_data/AICHA/1000099/AICHA_timeseries_NO_GSR_cormat.txt\"\n",
    "    aicha2 = pd.read_csv(aicha_test, sep=\";\", index_col=0)\n",
    "    \n",
    "    idx = get_idx(cat)\n",
    "    \n",
    "    if cat == \"edges\":\n",
    "        return list(aicha2.columns[idx]) #[x for x in list(aicha2.columns[idx]) if x in heritable]\n",
    "    elif cat == \"edges_HD\":\n",
    "        return list(x[:-2] for x in aicha2.columns[idx]) #[x for x in list(aicha2.columns[idx]) if x in heritable]\n",
    "\n",
    "\n",
    "def make_nice_mat(input_data, cat, var_name):\n",
    "    \"\"\"\n",
    "    put data from column into right spot in matrix\n",
    "    \"\"\"\n",
    "    #get indices\n",
    "    ind_names = get_names_aicha(cat)\n",
    "        \n",
    "    #set up dataframe\n",
    "    df_out = pd.DataFrame(index=ind_names, columns=ind_names)\n",
    "    df_out.iloc[np.diag_indices(len(ind_names)), np.diag_indices(len(ind_names))] = 0\n",
    "    \n",
    "    #put data in right place\n",
    "    for x in list(input_data.columns):\n",
    "        nodes = x.split(\"*\", 1)\n",
    "        df_out.loc[nodes[0], nodes[1]] = input_data.loc[var_name, x]\n",
    "        df_out.loc[nodes[1], nodes[0]] = input_data.loc[var_name, x]\n",
    "    \n",
    "    return df_out\n",
    "        \n",
    "    \n",
    "def plot_results_brain_cca(data, cat, brain_pheno, beh_pheno, ax, out=None):\n",
    "    \"\"\"\n",
    "    Main function:\n",
    "    - loads data\n",
    "    - significance testing\n",
    "    - plot using nilearn\n",
    "    \"\"\"\n",
    "    #get correlation values\n",
    "    load_mat = make_nice_mat(data, cat, beh_pheno)  \n",
    "    \n",
    "    #make colormap\n",
    "    colors = [\"mediumblue\", \"cornflowerblue\", \"lightgrey\", \"whitesmoke\", \"lightgrey\", \"lightcoral\", \"indianred\"]\n",
    "    cmap1 = LinearSegmentedColormap.from_list(\"mycmap\", colors)\n",
    "           \n",
    "    if vmax_in is None:\n",
    "        vmax_in = np.max(np.max(beta_mat))\n",
    "    \n",
    "    #plot\n",
    "    if np.abs(data.sum().sum()) < 0.0001:\n",
    "        plotting.plot_markers([1]*len(load_mat),\n",
    "                              set_up_coordinates(cat), \n",
    "                              node_cmap=\"binary\",\n",
    "                              node_size=30,\n",
    "                              alpha=0.8, \n",
    "                              display_mode='lyrz',\n",
    "                              axes=ax, \n",
    "                              title=beh_pheno[6:], \n",
    "                              colorbar=False)\n",
    "        \n",
    "    else:    \n",
    "        plotting.plot_connectome(load_mat.to_numpy(dtype=float),\n",
    "                             set_up_coordinates(cat),\n",
    "                             title=beh_pheno[6:],\n",
    "                             #edge_cmap=\"coolwarm\",\n",
    "                             edge_vmin=-vmax_in,\n",
    "                             edge_vmax=vmax_in,\n",
    "                             edge_cmap=cmap1,\n",
    "                             node_color=\"dimgrey\",\n",
    "                             node_size=30,\n",
    "                             display_mode=\"lyrz\",\n",
    "                             colorbar=True,\n",
    "                             alpha=0.8,\n",
    "                             axes=ax)\n",
    "                             #output_file=out)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd3e64-9555-46ea-a0c1-dc7c0f8a96e0",
   "metadata": {},
   "source": [
    "### 1. Process polygenic scores from PRS-cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61188b0e-e962-4a4a-927b-018fc5526bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgs = get_all_pgs(fn=\"/data/clusterfs/lag/users/jitame/SENT_CORE/geno/polygenic-scores/prs_out/{0}/{0}_prs_chr{1}.profile\",\n",
    "                  pheno_list=[\"read\", \"dyslexia\", \"hand\"])\n",
    "\n",
    "pgs[\"FID\"] = pgs[\"FID\"].astype(\"int\")\n",
    "pgs.set_index(\"FID\", inplace=True)\n",
    "pgs.to_csv(\"/data/clusterfs/lag/users/jitame/SENT_CORE/geno/polygenic-scores/all_scores_uncor.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a77f2ec3-09ff-481b-b545-8f3f5373ea20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. subjects missing from subject file:  1\n"
     ]
    }
   ],
   "source": [
    "covs=pd.read_csv(\"/data/clusterfs/lag/users/jitame/SENT_CORE/covars/covars_pc10_gwas.tsv\", sep=\"\\t\")\n",
    "covs[\"FID\"] = covs[\"FID\"].astype(\"int\")\n",
    "covs.set_index(\"FID\", inplace=True)\n",
    "covs.drop([\"IID\"], axis=1)\n",
    "covs=covs.dropna()\n",
    "\n",
    "normalized_pgs = residualize(pgs, covs)\n",
    "normalized_pgs.to_csv(\"/data/clusterfs/lag/users/jitame/SENT_CORE/geno/polygenic-scores/all_scores_norm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3f3eba-d4c3-4a78-bae6-27e5a8f87977",
   "metadata": {},
   "source": [
    "### 2a. Run CCA language network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e25b552-bfb2-4fb8-8203-584af65b3f71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29681, 630)\n",
      "(29681, 629)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                      | 0/3 [00:00<?, ?it/s]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      " 33%|███████████████████████████████████████████████████████████████▎                                                                                                                              | 1/3 [00:02<00:05,  2.54s/it]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      " 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                               | 2/3 [00:04<00:02,  2.45s/it]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:07<00:00,  2.45s/it]\n",
      "/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      "  0%|                                                                                                                                                                                                      | 0/3 [00:00<?, ?it/s]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      " 33%|███████████████████████████████████████████████████████████████▎                                                                                                                              | 1/3 [00:02<00:04,  2.28s/it]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      " 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                               | 2/3 [00:04<00:02,  2.29s/it]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:06<00:00,  2.29s/it]\n",
      "/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      "  0%|                                                                                                                                                                                                      | 0/3 [00:00<?, ?it/s]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      " 33%|███████████████████████████████████████████████████████████████▎                                                                                                                              | 1/3 [00:02<00:04,  2.34s/it]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      " 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                               | 2/3 [00:04<00:02,  2.35s/it]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:06<00:00,  2.32s/it]\n",
      "/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#settings\n",
    "n_perm = 3\n",
    "\n",
    "#load phenotypes\n",
    "brain_phenos = pd.read_csv(\"/data/clusterfs/lag/users/jitame/SENT_CORE/pheno/sent_edges_N29681_resid_norm.txt\",\n",
    "                     header=None,\n",
    "                     sep=\"\\t\",\n",
    "                     names=load_column_names(\"/data/clusterfs/lag/users/jitame/SENT_CORE/pheno/sent_edges_N_resid_col_names.txt\")\n",
    "                    )\n",
    "brain_phenos.set_index(\"Family_ID\", inplace=True)\n",
    "brain_phenos.drop(\"Subject_ID\",axis=1, inplace=True)\n",
    "\n",
    "her_names = load_column_names(os.path.join(\"/data/clusterfs/lag/users/jitame/SENT_CORE\", \"heritable_edges.txt\"))\n",
    "\n",
    "print(brain_phenos.shape)\n",
    "brain_phenos = brain_phenos[her_names]\n",
    "print(brain_phenos.shape)\n",
    "\n",
    "\n",
    "#set up stuff for CCA\n",
    "all_data = brain_phenos.join(normalized_pgs)\n",
    "\n",
    "brain_pheno_names = list(brain_phenos.columns)\n",
    "prs_pheno_names = list(normalized_pgs.columns)   \n",
    "\n",
    "df_null_dist = pd.DataFrame(columns=range(n_perm))\n",
    "df_corrs = pd.DataFrame(columns=\"R P\".split())\n",
    "df_loadings = pd.DataFrame(columns=brain_pheno_names)\n",
    "\n",
    "#run CCA\n",
    "for prs_pheno in prs_pheno_names:\n",
    "    df_corrs, df_loadings, df_null_dist = CCA_wrap(all_data,\n",
    "                                     df_loadings,\n",
    "                                     df_corrs,\n",
    "                                     df_null_dist,\n",
    "                                     prs_pheno,\n",
    "                                     brain_pheno_names,\n",
    "                                     n_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d047b965-6e8f-443a-ba12-bf95e66644a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29681, 153)\n",
      "(29681, 103)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                      | 0/3 [00:00<?, ?it/s]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      " 33%|███████████████████████████████████████████████████████████████▎                                                                                                                              | 1/3 [00:00<00:00,  4.04it/s]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      " 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                               | 2/3 [00:00<00:00,  4.34it/s]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.40it/s]\n",
      "/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      "  0%|                                                                                                                                                                                                      | 0/3 [00:00<?, ?it/s]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      " 33%|███████████████████████████████████████████████████████████████▎                                                                                                                              | 1/3 [00:00<00:00,  4.59it/s]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      " 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                               | 2/3 [00:00<00:00,  4.77it/s]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.58it/s]\n",
      "/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      "  0%|                                                                                                                                                                                                      | 0/3 [00:00<?, ?it/s]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      " 33%|███████████████████████████████████████████████████████████████▎                                                                                                                              | 1/3 [00:00<00:00,  4.33it/s]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      " 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                               | 2/3 [00:00<00:00,  4.69it/s]/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.75it/s]\n",
      "/home/jitame/bin/anaconda3/envs/results_env/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:503: FutureWarning: The attribute `coef_` will be transposed in version 1.3 to be consistent with other linear models in scikit-learn. Currently, `coef_` has a shape of (n_features, n_targets) and in the future it will have a shape of (n_targets, n_features).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#load asymmetries\n",
    "brain_phenos_asym = pd.read_csv(\"/data/clusterfs/lag/users/jitame/SENT_CORE/pheno/sent_edges_asym_N29681_resid_norm.txt\",\n",
    "                     header=None,\n",
    "                     sep=\"\\t\",\n",
    "                     names=load_column_names(\"/data/clusterfs/lag/users/jitame/SENT_CORE/pheno/sent_edges_asym_N_resid_col_names.txt\")\n",
    "                    )\n",
    "brain_phenos_asym.set_index(\"Family_ID\", inplace=True)\n",
    "brain_phenos_asym.drop(\"Subject_ID\",axis=1, inplace=True)\n",
    "\n",
    "her_names_asym = load_column_names(os.path.join(\"/data/clusterfs/lag/users/jitame/SENT_CORE\", \"heritable_edges_asym.txt\"))\n",
    "\n",
    "print(brain_phenos_asym.shape)\n",
    "brain_phenos_asym = brain_phenos_asym[her_names_asym]\n",
    "print(brain_phenos_asym.shape)\n",
    "\n",
    "#set up stuff\n",
    "all_data = brain_phenos_asym.join(normalized_pgs)\n",
    "\n",
    "brain_pheno_names = list(brain_phenos_asym.columns)\n",
    "prs_pheno_names = list(normalized_pgs.columns)   \n",
    "\n",
    "df_null_dist_asym = pd.DataFrame(columns=range(n_perm))\n",
    "df_corrs_asym = pd.DataFrame(columns=\"R P\".split())\n",
    "df_loadings_asym = pd.DataFrame(columns=brain_pheno_names)\n",
    "\n",
    "#run magic\n",
    "for prs_pheno in prs_pheno_names:\n",
    "    df_corrs_asym, df_loadings_asym, df_null_dist_asym = CCA_wrap(all_data,\n",
    "             df_loadings_asym,\n",
    "             df_corrs_asym,\n",
    "             df_null_dist_asym,\n",
    "             prs_pheno,\n",
    "             brain_pheno_names,\n",
    "             n_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b76292-b3b0-428e-b4f0-7e9d6970f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_corrs)\n",
    "sns.kdeplot(df_null_dist.T, bw_method=0.25)\n",
    "print(df_corrs_asym)\n",
    "sns.kdeplot(df_null_dist_asym.T, bw_method=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af2ce7f-05f9-4e82-90ed-723f71f24979",
   "metadata": {},
   "source": [
    "### 2b. Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfea60e7-d9e9-4c88-875e-e236dcc0cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_path = \"/data/workspaces/lag/workspaces/lg-ukbiobank/projects/rest-multimodal/results\"\n",
    "\n",
    "fig_args = {\"figsize\":(18,10),\"dpi\":300}\n",
    "\n",
    "fig, ax = plt.subplots(len(prs_pheno_names), 2, gridspec_kw={'height_ratios': [1]*len(prs_pheno_names)}, **fig_args)\n",
    "\n",
    "for x, pheno_name in enumerate(prs_pheno_names):\n",
    "    plot_results_brain_cca(data=df_loadings,\n",
    "                           cat=\"edges\",\n",
    "                           brain_pheno=\"edge\",\n",
    "                           beh_pheno=pheno_name,\n",
    "                           ax=ax[x, 0],\n",
    "                           out=None)\n",
    "    ax[x, 0].text(0.2, 0.94, \"R={:.3f}, P={:.3e}\".format(df_corrs.loc[pheno_name, \"R\"], df_corrs.loc[pheno_name, \"P\"]), fontsize=12)\n",
    "\n",
    "for x, pheno_name in enumerate(prs_pheno_names):\n",
    "    plot_results_brain_cca(data=df_loadings_asym,\n",
    "                           cat=\"edges_HD\",\n",
    "                           brain_pheno=\"edge hemispheric difference\",\n",
    "                           beh_pheno=pheno_name,\n",
    "                           ax=ax[x, 1],\n",
    "                           out=None)\n",
    "    \n",
    "    ax[x, 1].text(0.2, 0.94, \"R={:.3f}, P={:.3e}\".format(df_corrs_asym.loc[pheno_name, \"R\"], df_corrs_asym.loc[pheno_name, \"P\"]), fontsize=12)\n",
    "\n",
    "fig.suptitle(\"Multivariate associations of polygenic scores with brain phenotypes\", y=0.98, fontsize=24)\n",
    "ax[0, 0].text(0, 1.13, \"A. language network\", fontsize=16)\n",
    "ax[0, 1].text(0, 1.13, \"B. hemispheric differences\", fontsize=16)\n",
    "\n",
    "plt.savefig(fname=os.path.join(plot_path, \"CCA_results.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b44802-1b30-49c3-a767-2a8662945ef0",
   "metadata": {},
   "source": [
    "# check consistency between CCA and genetic correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1792e9-01c3-4ddb-a79d-a84147716997",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b3d41f-966f-49fa-92f8-69ac34818601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "def load_column_names(fn):\n",
    "    return [str(x) for x in open( fn ).read().split('\\n')[:-1] ]  \n",
    "\n",
    "def get_edge_names(list_names):\n",
    "    \"\"\"\n",
    "    Returns edge combinations for edges\n",
    "    \"\"\"\n",
    "    df_names=pd.DataFrame(index=list_names, columns=list_names)\n",
    "    for i in range(len(list_names)):\n",
    "        for j in range(len(list_names)):\n",
    "            df_names.iloc[i, j] = list_names[i]+\"*\"+list_names[j]\n",
    "            \n",
    "    heritable = load_column_names(\"/data/clusterfs/lag/users/jitame/SENT_CORE/heritable_edges.txt\") + load_column_names(\"/data/clusterfs/lag/users/jitame/SENT_CORE/heritable_edges_asym.txt\")\n",
    "    #heritable = [\"sent_edges_\"+x for x in heritable]\n",
    "    \n",
    "    return [x for x in list(df_names.to_numpy()[np.triu_indices(len(list_names), k=1)].flatten()) if x in heritable]\n",
    "\n",
    "def get_names_aicha(cat):\n",
    "    \"\"\"\n",
    "    Return node names\n",
    "    \"\"\"\n",
    "    aicha_test = \"/data/clusterfs/lag/projects/lg-ukbiobank/working_data/imaging_data/AICHA/1000099/AICHA_timeseries_NO_GSR_cormat.txt\"\n",
    "    aicha2 = pd.read_csv(aicha_test, sep=\";\", index_col=0)\n",
    "    \n",
    "    idx = get_idx(cat)\n",
    "    \n",
    "    if cat == \"edges\":\n",
    "        return list(aicha2.columns[idx]) #[x for x in list(aicha2.columns[idx]) if x in heritable]\n",
    "    elif cat == \"edges_HD\":\n",
    "        return [x[:-2] for x in list(aicha2.columns[idx])] \n",
    "    \n",
    "def get_hd_name(edge_name):\n",
    "    print(edge_name)\n",
    "    edge_split = edge_name.split(\"*\")\n",
    "    return edge_split[0][:-2]+\"*\"+edge_split[1][:-2]\n",
    "\n",
    "def data_loader_LDSC(fn, cat):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    #load data\n",
    "    data=pd.read_csv(fn)\n",
    "    \n",
    "    pheno = os.path.split(fn)[1][3:-20]\n",
    "    \n",
    "    #make edge names index\n",
    "    data[\"new_ind\"] = [os.path.split(x)[1].replace(\"reg2_gwas_sent_edges_\", \"\").replace(\".regenie.sumstats.gz\", \"\") for x in data.p2]\n",
    "    data.set_index(\"new_ind\", inplace=True)\n",
    "    \n",
    "    #select edges relevant to category\n",
    "    relevant_edges = get_edge_names(get_names_aicha(cat))\n",
    "    data = data.loc[relevant_edges, :]\n",
    "    data.columns = [x+\"_\"+pheno for x in data.columns]\n",
    "        \n",
    "    return data[\"rg_\"+pheno]\n",
    "    #return data\n",
    "\n",
    "def all_data_rg(file_list, cat):\n",
    "    return pd.concat(map(data_loader_LDSC, file_list, [cat]*3),axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4058e0f8-b355-4392-9d50-6c440629b71e",
   "metadata": {},
   "source": [
    "### Language network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab59a7b-1c02-4bb2-ab4b-7caf3b03b2dc",
   "metadata": {},
   "source": [
    "#### RG vs. CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798b2b49-9c81-413c-b823-0255fbd3466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/data/clusterfs/lag/users/jitame/SENT_CORE/geno\"\n",
    "ldsc_path = os.path.join(base_path, \"ldsc/rg/external\")\n",
    "\n",
    "pheno_list = [\"read\", \"dyslexia\", \"hand\"]\n",
    "\n",
    "file_names = [os.path.join(ldsc_path, \"rg_\"+pheno+\".txt.sumstats.gz.csv\") for pheno in pheno_list]\n",
    "\n",
    "rg_data = all_data_rg(file_names, cat=\"edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b91bd3e-dafb-48ec-8746-f791880b6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_cca = rg_data.join(df_loadings.T)\n",
    "rg_cca.corr().to_csv(os.path.join(plot_path, \"cca_rg_corrs.csv\"))\n",
    "sns.heatmap(rg_cca.corr(), cmap=\"coolwarm\", vmin=-1,vmax=1, annot=True)\n",
    "plt.savefig(fname=os.path.join(plot_path, \"CCA_vs_rg_heatmap.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a59ff1-a26e-4c9a-8b14-2a1621f74a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(rg_cca)\n",
    "plt.savefig(fname=os.path.join(plot_path, \"CCA_vs_rg.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affaedbb-513f-4f27-944e-48e5b3f91148",
   "metadata": {},
   "source": [
    "#### CCA vs. univariate correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4161bb3d-3840-466d-a1bc-52372e282a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_corrs = pd.concat([brain_phenos.corrwith(normalized_pgs.score_dyslexia), brain_phenos.corrwith(normalized_pgs.score_hand), brain_phenos.corrwith(normalized_pgs.score_read)],axis=1)\n",
    "uni_corrs.columns = [\"uni_read\", \"uni_dyslexia\", \"uni_hand\"]\n",
    "corrs_cca = uni_corrs.join(df_loadings.T)\n",
    "corrs_cca.corr().to_csv(os.path.join(plot_path, \"uni_corrs_cca_corrs.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe62d1e-d792-4c95-978e-3e0ec7be3250",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(corrs_cca)\n",
    "plt.savefig(fname=os.path.join(plot_path, \"CCA_vs_uni_corrs.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9570fc7a-b309-416b-9ef6-2c9a42608a68",
   "metadata": {},
   "source": [
    "## Asymmetries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd526486-98a6-4c42-bfe3-03de269859d9",
   "metadata": {},
   "source": [
    "#### RG vs. CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca9af5-18f9-4daf-b6c0-cd6083973582",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_data_asym = all_data_rg(file_names, cat=\"edges_HD\")\n",
    "rg_cca_asym = rg_data_asym.join(df_loadings_asym.T)\n",
    "rg_cca_asym.corr().to_csv(os.path.join(plot_path, \"cca_rg_asym_corrs.csv\"))\n",
    "sns.heatmap(rg_cca_asym.corr(), cmap=\"coolwarm\", vmin=-1,vmax=1, annot=True)\n",
    "plt.savefig(fname=os.path.join(plot_path, \"CCA_vs_rg_asym_heatmap.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca71959-d13b-447c-9a20-897acc568d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(rg_cca_asym)\n",
    "plt.savefig(fname=os.path.join(plot_path, \"CCA_vs_rg_asym.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81f2b2b-6b6f-41ac-8343-6355a8eee430",
   "metadata": {},
   "source": [
    "#### CCA vs. univariate correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4078fac7-e4e5-46a7-94f4-67f2e388b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_corrs_asym = pd.concat([brain_phenos_asym.corrwith(normalized_pgs.score_dyslexia), brain_phenos_asym.corrwith(normalized_pgs.score_hand), brain_phenos_asym.corrwith(normalized_pgs.score_read)],axis=1)\n",
    "uni_corrs_asym.columns = [\"uni_read\", \"uni_dyslexia\", \"uni_hand\"]\n",
    "corrs_cca_asym = uni_corrs_asym.join(df_loadings_asym.T)\n",
    "corrs_cca_asym.corr().to_csv(os.path.join(plot_path, \"uni_corrs_cca_corrs_asym.csv\"))\n",
    "corrs_cca_asym.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745ea245-6feb-4b1b-8402-dee0f580ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(corrs_cca_asym)\n",
    "plt.savefig(fname=os.path.join(plot_path, \"CCA_vs_uni_corrs_asym.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f1b57-55df-41ce-bd67-96f85ad97253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:results_env]",
   "language": "python",
   "name": "conda-env-results_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
